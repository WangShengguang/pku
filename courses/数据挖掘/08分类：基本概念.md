# 数据挖掘

## 分类：基本概念

## 8.1基本概念

#### 8.1什么是分类

分类和数值预测是预测问题的两种主要类型

- 分类：分类器

- 数值预测：预测器；回归分析（regression analysis）是常用数值预测方法

#### 8.1.2分类的一般方法

数据分类包括两个阶段：

- 学习阶段（构建分类模型）
- 分类阶段（使用模型预测给定数据的类标号）



##### 1.学习阶段

简历描述预先定义的数据类或概念集的分类器。**分类算法**通过分析或从训练集“学习”来构造分类器。**训练集**由数据库元组和与他们关联的类标号组成。元组X用n维属性向量X=(x1,x2,...,xn)表示。假定每个元素X都属于一个预先定义的类，由一个称为类标号属性（class label attribute）的数据库属性确定。类标号值时离散的和无序的，每个值充当一个类别或类。构成训练数据集的元组称为训练元组，从数据库中随机选取。分类问题中，数据元组也称为样本、实例、数据点或对象。

监督学习：提供了每个元组的类标号

非监督学习（聚类）：训练元组标号未知



##### 2.分类阶段

使用模型进行分类。过拟合、检验集、准确率



### 8.2决策树归纳

从有标号的训练元组中学习决策树。

#### 8.2.1决策树归纳

迭代的二分器（Iterative Dichotomiser，ID3）  &rarr;   C4.5  &rarr; Classification and Regression Trees （CART）

都采用贪心（非回溯）方法，其中决策树以自顶向下递归的分治方式构造。

#### 8.2.2属性选择度量

属性选择度量是一种选择分类准则，把给定类标记的训练元组的数据分区D“最好地”划分成单独类的启发式方法。

1. 信息增益

   ID3使用信息增益作为属性选择度量。基于香农信息论的工作

   分裂点

2. 增益率

   信息增益度量偏向具有许多输出的测试。倾向于选择具有大量值的属性。分出的类较多。

3. 基尼指数

   Gini index在CART中使用。

4. 其他属性选择度量

#### 8.2.3属性剪枝

先剪枝和后剪枝

- 先剪枝

  提前停止树的构建

- 后剪枝

  由“完全生长”的树剪去子树。

  CART：代价复杂度剪枝法

  C4.5悲观剪枝



#### 8.2.4 可伸缩性与决策树归纳

内存换进换出

#### 8.2.5 决策树归纳的可视化挖掘

在每个节点，每个属性维护一个AVC集（AVC表示“属性-值”，类标号）





### 8.3贝叶斯分类方法

#### 8.3.1 贝叶斯定理

- P(H|X)后验概率

- P(H)先验概率

#### 8.3.2 朴素贝叶斯分类



### 8.4基于规则的分类

#### 8.4.1 使用IF-THEN规则分类

一个IF-THEN规则是一个表达式：IF 条件 THEN 结论

规则的IF部分（或左部分）称为规则前件或前提。THEN 部分（或右侧）是规则的结论

例：R1：IF age=youth AND student=yes THEN buys_computer=yes

对给定元祖，若规则前件的条件（属性测试）都成立，则我们说规则前件被满足（或简单地，规则被满足），并**覆盖**了该元组。

对数据集D, 规则R；记n_correct为正确分类的元组数，n_covers为R覆盖的元组数，|D|为D元组数：

- 覆盖率：coverage(R)=n_covers/|D|

- 准确率：accuracy(R)=n_correct/n_covers

#### 8.4.2 由决策树提取规则

#### 8.4.3 使用顺序覆盖算法的规则归纳

一次学习一个规则。每学习一个规则，就删除该规则覆盖的元组，并在剩下的元组上重复该过程。

### 8.5模型评估与选择

#### 8.5.1 评估分类器性能的度量

准确率（识别率）、敏感度（召回率）、特效性、精度、F<sub>1</sub>和F<sub>β</sub> 。

**术语**：

- 真正例（True Positive，TP）：被分类器正确分类的正元组。令TP=真正例的个数。

- 真负例（True Negative，TN）：被分类器正确分类的负元组。令TN=真负例的个数。

- 假正例（False Positive，FP）：被分类器错误分类为正元组的负元组。令FP=假正例的个数。

- 假负例（False Negative，FN）：被分类器错误分类为负元组的正元组。令FN=假负例的个数。

**度量**：

- 准确率（识别率）：

$$
accuracy=\frac{TP+TN}{P+N}
$$

- 错误率
$$
error rate=\frac{FP+FN}{P+N}
$$

- 灵敏性：真正例识别率
$$
sensitivity=\frac{TP}{P}
$$

- 特效性：真负例识别率
$$
specificity=\frac{TN}{N}
$$

- 精度（precision）:精确性度量
$$
precision = \frac{TP}{TP+FP}
$$
- 召回率（recall）：完整性度量==灵敏度
$$
recall = \frac{TP}{TP+FN}=\frac{TP}{P}
$$

- F度量（又称F<sub>1</sub>分数或F分数）和F<sub>β</sub>度量

$$
F = \frac{2\times precision \times recall}{precision+recall}
$$
$$
F = \frac{(1+\beta^2)\times precision \times recall}{\beta^2 \times precision+recall}
$$

]



#### 8.5.2 保持方法和随机二次抽样





### 8.6提高分类准确率的技术

